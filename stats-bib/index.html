<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <title>ryan y wang</title>
    <link rel="stylesheet" type="text/css" href="../static/style.css">    
    <script type="text/javascript">
      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-47452844-1']);
      _gaq.push(['_trackPageview']);
      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();
    </script>
  </head>
  <body>
      <div class="container">
        <div class="header">
          ryan y wang || stats-bib
        </div>
        <div class="nav">
          <ul>
            <li><a href="../about/index.html">about</a>
            <li><a href="../blog/index.html">blog</a>
            <li><a href="../projects/index.html">projects</a>
            <li><a href="../self/index.html">quantified self</a>
          </ul>
        </div>
        <div class="body">
                      
            <h2>Undergraduate Statistics Bibliography</h2>
<p>The below is an annotated bibliography for studying statistics. My hope is that it can be useful for those interested in a rigorous undergraduate-level statistics education. I've found that nothing beats pen, paper, and a <em>good</em> textbook when it comes to really learning a subject (as much as I love MOOCs). Books are listed in roughly descending order of difficulty within each subject area. This is inspired by the <a href="http://www.ocf.berkeley.edu/~abhishek/chicmath.htm">Chicago undergraduate mathematics bibliography</a>. </p>
<p>Please do let me know if you'd like to add a blurb.</p>
<p><strong> Foundations: Probability </strong></p>
<p><em>Ross, A first course in probability:</em> The title is perfectly descriptive. Other introductory books are perhaps just as good but this one certainly covers the basics.</p>
<p><em>Feller, An introduction to probability theory and its applications (Vol. 1):</em> A classic. Feller goes deeply into discrete probability with many examples along the way. The exercises are especially good.</p>
<p><em>Feller, An introduction to probability theory and its applications (Vol. 2); Billingsley, Probability and measure:</em> Measure-theoretic probability. Have never gotten very far into either of these. </p>
<p><em>Williams, Probability with martingales:</em> Another treatment of measure-theoretic probability. Concise and clear, but very dense. A good companion book.</p>
<p><strong> Foundations: Mathematical statistics </strong></p>
<p><em>Rice, Mathematical statistics and data analysis:</em> The required text for my first statistics course. Covers the basics from the Law of Large Numbers and the Central Limit Theorem to methods of inference.</p>
<p><em>Faraway, Linear models with R; Faraway, Extending the linear model with R:</em> A very practical, hands-on set of books. Works through numerous data analysis examples.</p>
<p><em>McCullagh and Nelder, Generalized linear models:</em> A mix of application and theory. Ties together the various types of regression e.g. linear, logistic, poisson. Another classic, though the examples feel a bit dated.</p>
<p><em>Casella and Berger, Statistical inference:</em> Covers classical statistical theory, typically for first-year PhDs. Good for a second run through mathematical statistics.</p>
<p><em>Wasserman, All of statistics; Wasserman, All of nonparametric statistics:</em> Both are short cookbook-type texts. Focused on theory unlike the Faraway books.</p>
<p><strong> Topics: Bayesian Statistics </strong></p>
<p><em>Gelman et al, Bayesian data analysis:</em> A very applied book with numerous data analysis examples. Covers the widely used modern methods.</p>
<p><em>Berger, Statistical decision theory and bayesian analysis:</em> A good mathematical introduction to Bayesian reasoning. Does feel a bit dated. Published in 1993 and there have been many advances in applications since then, esp. in terms of computation.</p>
<p><strong> Topics: Computation </strong></p>
<p><em>Nocedal and Wright, Numerical optimization:</em> Written for engineers. A good introduction to general methods for both constrained and unconstrained optimization.</p>
<p><em>Boyd and Vandenberghe, Convex optimization:</em> Excellent book with great exercises. Focused more on mathematical understanding and less on algorithmic implementation. I think this is a good thing, because how many people are going to implement their own solver?</p>
<p><strong> Topics: History </strong></p>
<p><em>Salsburg, The lady tasting tea:</em> Entertaining account of the main personalities behind classical statistics - Fisher, Neyman, Pearson - and their interrelationships.</p>
<p><em>Stigler, The history of statistics:</em> Written by a statistician, goes into the actual mathematics. A comprehensive account up until the time of Galton.  </p>
<p><strong> Topics: Machine Learning </strong></p>
<p><em>Hastie et al, Elements of statistical learning:</em> Clearly written introduction to a grab-bag of techniques. Focused on application. Also freely available <a href="http://statweb.stanford.edu/~tibs/ElemStatLearn/">online</a></p>
<p><em>Bishop, Pattern recognition and machine learning:</em> A more mathematical treatment of most of the techniques in the above.</p>          
          
        </div>
      </div>
  </body>
</html>